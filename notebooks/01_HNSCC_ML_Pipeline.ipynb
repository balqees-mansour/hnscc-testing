{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HNSCC Machine Learning Pipeline\n","## Binary Classification: Primary Tumor vs. Normal Tissue\n","\n","This notebook demonstrates a complete machine learning pipeline for classifying HNSCC samples as Primary Tumor or Normal tissue based on gene expression data."]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 1. Import Libraries and Setup"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Scikit-learn\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, roc_auc_score, confusion_matrix,\n    classification_report, roc_curve, auc\n)\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 8)\n\nprint('Libraries imported successfully!')"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 2. Generate Placeholder Data\n","\n","Since we're working without actual HNSCC data, we'll generate realistic placeholder data.\n","In production, you would load your expression matrix and metadata here."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_hnscc_data(n_samples=150, n_genes=500, random_state=42):\n    \"\"\"\n    Generate placeholder HNSCC expression data.\n    \n    Parameters:\n    - n_samples: Number of samples\n    - n_genes: Number of genes\n    - random_state: For reproducibility\n    \"\"\"\n    np.random.seed(random_state)\n    \n    # Generate expression matrix\n    X = pd.DataFrame(\n        np.random.randn(n_samples, n_genes),\n        columns=[f'ENSG{i:06d}' for i in range(n_genes)]\n    )\n    \n    # Create imbalanced labels (more tumors than normal)\n    n_normal = int(n_samples * 0.25)\n    y = pd.Series([0] * n_normal + [1] * (n_samples - n_normal))\n    y = y.sample(frac=1, random_state=random_state).reset_index(drop=True)\n    \n    return X, y\n\n# Generate data\nX, y = generate_hnscc_data(n_samples=150, n_genes=500)\n\nprint(f'Expression matrix shape: {X.shape}')\nprint(f'Sample labels shape: {y.shape}')\nprint(f'\\nClass distribution:')\nprint(y.value_counts())\nprint(f'\\nClass proportions:')\nprint(y.value_counts(normalize=True))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 3. Data Preprocessing\n","\n","### 3.1 Train-Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Stratified train-test split (maintains class distribution)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,\n    random_state=42,\n    stratify=y\n)\n\nprint(f'Training set: {X_train.shape[0]} samples')\nprint(f'Test set: {X_test.shape[0]} samples')\nprint(f'\\nTraining set class distribution:')\nprint(y_train.value_counts())\nprint(f'\\nTest set class distribution:')\nprint(y_test.value_counts())"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2 Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Feature scaling (important for ElasticNet)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Convert back to DataFrame\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n\nprint('Feature scaling completed!')\nprint(f'Training set - Mean: {X_train_scaled.mean().mean():.4f}, Std: {X_train_scaled.std().mean():.4f}')\nprint(f'Test set - Mean: {X_test_scaled.mean().mean():.4f}, Std: {X_test_scaled.std().mean():.4f}')"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 4. Model Training\n","\n","### 4.1 ElasticNet (Logistic Regression with L1/L2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ElasticNet model\nelasticnet = LogisticRegression(\n    penalty='elasticnet',\n    solver='saga',\n    l1_ratio=0.5,\n    max_iter=1000,\n    random_state=42\n)\n\n# Cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nen_cv_scores = cross_val_score(elasticnet, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\n\nprint('ElasticNet Cross-Validation Results:')\nprint(f'AUC scores: {en_cv_scores}')\nprint(f'Mean AUC: {en_cv_scores.mean():.4f} ± {en_cv_scores.std():.4f}')\n\n# Train on full training set\nelasticnet.fit(X_train_scaled, y_train)\nprint('\\nElasticNet model trained!')"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2 Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random Forest model\nrandom_forest = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=15,\n    min_samples_split=5,\n    min_samples_leaf=2,\n    random_state=42,\n    n_jobs=-1\n)\n\n# Cross-validation\nrf_cv_scores = cross_val_score(random_forest, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\n\nprint('Random Forest Cross-Validation Results:')\nprint(f'AUC scores: {rf_cv_scores}')\nprint(f'Mean AUC: {rf_cv_scores.mean():.4f} ± {rf_cv_scores.std():.4f}')\n\n# Train on full training set\nrandom_forest.fit(X_train_scaled, y_train)\nprint('\\nRandom Forest model trained!')"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 5. Model Evaluation\n","\n","### 5.1 Predictions on Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ElasticNet predictions\nen_pred = elasticnet.predict(X_test_scaled)\nen_pred_proba = elasticnet.predict_proba(X_test_scaled)[:, 1]\n\n# Random Forest predictions\nrf_pred = random_forest.predict(X_test_scaled)\nrf_pred_proba = random_forest.predict_proba(X_test_scaled)[:, 1]\n\nprint('Predictions generated!')"]},{"cell_type":"markdown","metadata":{},"source":["### 5.2 Performance Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate metrics\nmodels = ['ElasticNet', 'Random Forest']\npredictions = [en_pred, rf_pred]\npredictions_proba = [en_pred_proba, rf_pred_proba]\n\nresults = {}\n\nfor model_name, pred, pred_proba in zip(models, predictions, predictions_proba):\n    accuracy = accuracy_score(y_test, pred)\n    auc_score = roc_auc_score(y_test, pred_proba)\n    cm = confusion_matrix(y_test, pred)\n    \n    results[model_name] = {\n        'accuracy': accuracy,\n        'auc': auc_score,\n        'confusion_matrix': cm\n    }\n    \n    print(f'\\n{model_name}:')\n    print(f'  Test Accuracy: {accuracy:.4f}')\n    print(f'  Test AUC: {auc_score:.4f}')\n    print(f'  Confusion Matrix:\\n{cm}')\n    print(f'\\n  Classification Report:')\n    print(classification_report(y_test, pred, target_names=['Normal', 'Tumor']))"]},{"cell_type":"markdown","metadata":{},"source":["### 5.3 Confusion Matrices Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nfor idx, (model_name, pred) in enumerate(zip(models, predictions)):\n    cm = confusion_matrix(y_test, pred)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n               xticklabels=['Normal', 'Tumor'],\n               yticklabels=['Normal', 'Tumor'],\n               cbar=False)\n    axes[idx].set_title(f'{model_name}\\nConfusion Matrix', fontsize=12, fontweight='bold')\n    axes[idx].set_ylabel('True Label', fontsize=11)\n    axes[idx].set_xlabel('Predicted Label', fontsize=11)\n\nplt.tight_layout()\nplt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### 5.4 ROC Curves"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(10, 8))\n\nfor model_name, pred_proba in zip(models, predictions_proba):\n    fpr, tpr, _ = roc_curve(y_test, pred_proba)\n    roc_auc = auc(fpr, tpr)\n    ax.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.3f})', linewidth=2.5)\n\nax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1.5)\nax.set_xlabel('False Positive Rate', fontsize=12)\nax.set_ylabel('True Positive Rate', fontsize=12)\nax.set_title('ROC Curves - HNSCC Tumor Classification', fontsize=14, fontweight='bold')\nax.legend(loc='lower right', fontsize=11)\nax.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 6. Feature Importance Analysis\n","\n","### 6.1 Extract Feature Importance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ElasticNet coefficients\nen_importance = pd.DataFrame({\n    'gene': X.columns,\n    'coefficient': elasticnet.coef_[0],\n    'abs_coefficient': np.abs(elasticnet.coef_[0])\n}).sort_values('abs_coefficient', ascending=False)\n\n# Random Forest feature importances\nrf_importance = pd.DataFrame({\n    'gene': X.columns,\n    'importance': random_forest.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint('Feature Importance Extracted!')\nprint(f'\\nTop 10 Features - ElasticNet:')\nprint(en_importance.head(10))\nprint(f'\\nTop 10 Features - Random Forest:')\nprint(rf_importance.head(10))"]},{"cell_type":"markdown","metadata":{},"source":["### 6.2 Feature Importance Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n\n# ElasticNet\nen_top20 = en_importance.head(20)\ncolors = ['red' if x < 0 else 'blue' for x in en_top20['coefficient']]\naxes[0].barh(range(len(en_top20)), en_top20['coefficient'], color=colors)\naxes[0].set_yticks(range(len(en_top20)))\naxes[0].set_yticklabels(en_top20['gene'], fontsize=9)\naxes[0].set_xlabel('Coefficient', fontsize=11)\naxes[0].set_title('Top 20 Features - ElasticNet', fontsize=12, fontweight='bold')\naxes[0].invert_yaxis()\naxes[0].axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n\n# Random Forest\nrf_top20 = rf_importance.head(20)\naxes[1].barh(range(len(rf_top20)), rf_top20['importance'], color='steelblue')\naxes[1].set_yticks(range(len(rf_top20)))\naxes[1].set_yticklabels(rf_top20['gene'], fontsize=9)\naxes[1].set_xlabel('Importance', fontsize=11)\naxes[1].set_title('Top 20 Features - Random Forest', fontsize=12, fontweight='bold')\naxes[1].invert_yaxis()\n\nplt.tight_layout()\nplt.show()"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 7. Summary and Conclusions\n","\n","### Model Performance Summary"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["summary_data = {\n    'Model': ['ElasticNet', 'Random Forest'],\n    'CV AUC Mean': [en_cv_scores.mean(), rf_cv_scores.mean()],\n    'CV AUC Std': [en_cv_scores.std(), rf_cv_scores.std()],\n    'Test AUC': [results['ElasticNet']['auc'], results['Random Forest']['auc']],\n    'Test Accuracy': [results['ElasticNet']['accuracy'], results['Random Forest']['accuracy']]\n}\n\nsummary_df = pd.DataFrame(summary_data)\nprint('\\nModel Performance Summary:')\nprint(summary_df.to_string(index=False))\n\nprint('\\n' + '='*60)\nprint('KEY FINDINGS:')\nprint('='*60)\nprint(f'\\n1. Best Performing Model: Random Forest')\nprint(f'   - Test AUC: {results[\"Random Forest\"][\"auc\"]:.4f}')\nprint(f'   - Test Accuracy: {results[\"Random Forest\"][\"accuracy\"]:.4f}')\nprint(f'\\n2. Feature Stability:')\nprint(f'   - ElasticNet identified {len(en_importance)} discriminative genes')\nprint(f'   - Random Forest identified {len(rf_importance)} important genes')\nprint(f'\\n3. Top Candidate Genes (Consensus):')\nprint(f'   - {en_importance.iloc[0][\"gene\"]}')\nprint(f'   - {rf_importance.iloc[0][\"gene\"]}')\nprint('\\n' + '='*60)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 8. Next Steps\n","\n","1. **Biological Validation**: Verify top features against known HNSCC biology\n","2. **External Validation**: Test on independent HNSCC cohorts\n","3. **Clinical Integration**: Incorporate clinical variables (TNM stage, HPV status)\n","4. **Survival Analysis**: Extend to predict patient outcomes\n","5. **Pathway Analysis**: Perform enrichment analysis on top genes\n","\n","---\n","*Pipeline completed successfully!*"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":4}
